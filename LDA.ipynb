{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import string\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "Note: This requires `wget` and `unzip` to be installed on your system.\n",
    "\n",
    "It retrieves data from http://www.cs.cornell.edu/people/pabo/movie-review-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subprocess.call(\"./get_data.sh\", shell=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "\n",
    "This reads in each speech as a list of words. In particular, it removes all punctuation, stopwords, lower-cases all the words, and splits on white space. Please be aware that you must have `nltk` installed on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    subdirs = os.listdir('scale_whole_review')\n",
    "    \n",
    "    docs = []\n",
    "    for n in subdirs:\n",
    "        new_base = 'scale_whole_review/' + n + '/txt.parag/'\n",
    "        files = os.listdir(new_base)\n",
    "        for file in files:\n",
    "            with open(new_base + file, 'rb') as f:\n",
    "                docs.append(str(f.read()))\n",
    "            \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    docs = [doc.translate(translator).lower().split() for doc in docs]\n",
    "    docs = [[w for w in doc if w not in stops] for doc in docs]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the collapsed gibbs sampler\n",
    "\n",
    "See slides [here](https://n-s-f.github.io/talks/lda.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gibbs(docs, num_topics, iterations=5000):\n",
    "    num_docs = len(docs)\n",
    "    \n",
    "    corpus = list(set(chain(*docs)))\n",
    "    num_words = len(corpus)\n",
    "    corpus_lookup = dict(zip(corpus, range(num_words)))\n",
    "    \n",
    "    alpha = 1 / num_topics  # flat prior\n",
    "    beta = 1 / num_words  # flat prior\n",
    "    \n",
    "    \n",
    "    # Assuming flat priors\n",
    "    # Randomly initialize topic allocations\n",
    "    current_topics = [np.random.randint(0, num_topics, len(words))\n",
    "                      for words in docs]\n",
    "     \n",
    "    # Update counts\n",
    "    topic_counts = np.zeros(num_topics)\n",
    "    for doc_topics in current_topics:\n",
    "        for topic in doc_topics:\n",
    "            topic_counts[topic] += 1\n",
    "\n",
    "    document_counts = np.zeros((num_docs, num_topics))    \n",
    "    for d, topics in enumerate(current_topics):\n",
    "        for t in range(num_topics):\n",
    "            document_counts[d][t] = sum(topics == t)\n",
    "            \n",
    "    word_counts = np.zeros((num_topics, num_words))\n",
    "    for d, doc in enumerate(docs):\n",
    "        for w, word in enumerate(doc):\n",
    "            topic = current_topics[d][w]\n",
    "            word_id = corpus_lookup[word]\n",
    "            word_counts[topic][word_id] += 1\n",
    "            \n",
    "    # Begin the Gibbs sampler proper\n",
    "    for it in range(iterations):\n",
    "        if it % 10 == 0:\n",
    "            print('iteration:', it)\n",
    "        \n",
    "        for d, doc in enumerate(docs):\n",
    "            for w, word in enumerate(doc):\n",
    "                topic = current_topics[d][w]\n",
    "                document_counts[d][topic] -= 1\n",
    "                word_counts[topic][corpus_lookup[word]] -= 1\n",
    "                topic_counts[topic] -= 1\n",
    "\n",
    "                probs = np.zeros(num_topics)\n",
    "                \n",
    "                # Quadruple nested for loop! \n",
    "                for j in range(num_topics):\n",
    "                    probs[j] = ((\n",
    "                    (document_counts[d][j] + alpha)\n",
    "                     * (word_counts[j][corpus_lookup[word]] + beta))\n",
    "                     / (topic_counts[j] + (beta * num_words)))\n",
    "\n",
    "                probs = probs / np.sum(probs)\n",
    "                new_topic = np.where(np.random.multinomial(1, probs))[0][0]\n",
    "                current_topics[d][w] = new_topic\n",
    "                document_counts[d][new_topic] += 1\n",
    "                word_counts[new_topic][corpus_lookup[word]] += 1\n",
    "                topic_counts[new_topic] += 1\n",
    "\n",
    "    return current_topics, document_counts, word_counts, topic_counts, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct topics\n",
    "\n",
    "Given how often each word appears in a topic, we can reconstruct the distributions of words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_topics(results):\n",
    "    topic_distributions = []\n",
    "    for topic in range(results[2].shape[0]):\n",
    "        percentages = results[2][topic] / np.sum(results[2][topic])\n",
    "        dist = sorted(list(zip(results[4], percentages)), key=lambda x: -x[1])\n",
    "        topic_distributions.append(dist)\n",
    "    return topic_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analyze the data\n",
    "\n",
    "We'll assume there are 30 topics overall in the movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 10\n",
      "iteration: 20\n",
      "iteration: 30\n",
      "iteration: 40\n",
      "iteration: 50\n",
      "iteration: 60\n",
      "iteration: 70\n",
      "iteration: 80\n",
      "iteration: 90\n",
      "iteration: 100\n",
      "iteration: 110\n",
      "iteration: 120\n",
      "iteration: 130\n",
      "iteration: 140\n",
      "iteration: 150\n",
      "iteration: 160\n",
      "iteration: 170\n",
      "iteration: 180\n",
      "iteration: 190\n",
      "iteration: 200\n",
      "iteration: 210\n",
      "iteration: 220\n",
      "iteration: 230\n",
      "iteration: 240\n",
      "iteration: 250\n",
      "iteration: 260\n",
      "iteration: 270\n",
      "iteration: 280\n",
      "iteration: 290\n",
      "iteration: 300\n",
      "iteration: 310\n",
      "iteration: 320\n",
      "iteration: 330\n",
      "iteration: 340\n",
      "iteration: 350\n",
      "iteration: 360\n",
      "iteration: 370\n",
      "iteration: 380\n",
      "iteration: 390\n",
      "iteration: 400\n",
      "iteration: 410\n",
      "iteration: 420\n",
      "iteration: 430\n",
      "iteration: 440\n",
      "iteration: 450\n",
      "iteration: 460\n",
      "iteration: 470\n",
      "iteration: 480\n",
      "iteration: 490\n"
     ]
    }
   ],
   "source": [
    "docs = read_data()\n",
    "results = gibbs(docs, num_topics=30, iterations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_distributions = reconstruct_topics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['film',\n",
       "  'little',\n",
       "  'characters',\n",
       "  'time',\n",
       "  'two',\n",
       "  'much',\n",
       "  'first',\n",
       "  'way',\n",
       "  'short',\n",
       "  'everything'],\n",
       " ['come',\n",
       "  'way',\n",
       "  'film',\n",
       "  'get',\n",
       "  'make',\n",
       "  'peter',\n",
       "  'attack',\n",
       "  'bill',\n",
       "  'williams',\n",
       "  'three'],\n",
       " ['little',\n",
       "  'like',\n",
       "  'one',\n",
       "  'john',\n",
       "  'humor',\n",
       "  'enough',\n",
       "  'big',\n",
       "  'comedy',\n",
       "  'david',\n",
       "  'much'],\n",
       " ['film',\n",
       "  'part',\n",
       "  'play',\n",
       "  'actors',\n",
       "  'director',\n",
       "  'richard',\n",
       "  'role',\n",
       "  'first',\n",
       "  'music',\n",
       "  'one'],\n",
       " ['one',\n",
       "  'man',\n",
       "  'film',\n",
       "  'films',\n",
       "  'story',\n",
       "  'life',\n",
       "  'young',\n",
       "  'novel',\n",
       "  'character',\n",
       "  'makes'],\n",
       " ['love',\n",
       "  'life',\n",
       "  'story',\n",
       "  'two',\n",
       "  'one',\n",
       "  'woman',\n",
       "  'wife',\n",
       "  'film',\n",
       "  'husband',\n",
       "  'man'],\n",
       " ['film',\n",
       "  'one',\n",
       "  'even',\n",
       "  'life',\n",
       "  'like',\n",
       "  'still',\n",
       "  'things',\n",
       "  'something',\n",
       "  'much',\n",
       "  'find'],\n",
       " ['movie',\n",
       "  'like',\n",
       "  'would',\n",
       "  'sex',\n",
       "  'drug',\n",
       "  'film',\n",
       "  'big',\n",
       "  'one',\n",
       "  'video',\n",
       "  'free'],\n",
       " ['film',\n",
       "  'father',\n",
       "  'story',\n",
       "  'family',\n",
       "  'mother',\n",
       "  'young',\n",
       "  'doesnt',\n",
       "  'see',\n",
       "  'without',\n",
       "  'home'],\n",
       " ['jack',\n",
       "  'game',\n",
       "  'new',\n",
       "  'play',\n",
       "  'one',\n",
       "  'like',\n",
       "  'plays',\n",
       "  'life',\n",
       "  'comedy',\n",
       "  'even'],\n",
       " ['us',\n",
       "  'movie',\n",
       "  'theres',\n",
       "  'director',\n",
       "  'screenplay',\n",
       "  'music',\n",
       "  'however',\n",
       "  'picture',\n",
       "  'cinematography',\n",
       "  'motion'],\n",
       " ['hes',\n",
       "  'much',\n",
       "  'like',\n",
       "  'plot',\n",
       "  'action',\n",
       "  'doesnt',\n",
       "  'bad',\n",
       "  'michael',\n",
       "  'script',\n",
       "  'time'],\n",
       " ['part',\n",
       "  'new',\n",
       "  'first',\n",
       "  'chan',\n",
       "  'jackie',\n",
       "  'gets',\n",
       "  'hard',\n",
       "  'action',\n",
       "  'number',\n",
       "  'two'],\n",
       " ['dennis',\n",
       "  'film',\n",
       "  'reserved',\n",
       "  'schwartz',\n",
       "  'rights',\n",
       "  'schwartzn',\n",
       "  'ozus',\n",
       "  'reviewsnxa9',\n",
       "  'tells',\n",
       "  'police'],\n",
       " ['comedy',\n",
       "  'one',\n",
       "  'max',\n",
       "  'around',\n",
       "  'day',\n",
       "  'gets',\n",
       "  'tv',\n",
       "  'couple',\n",
       "  'funny',\n",
       "  'smith'],\n",
       " ['war',\n",
       "  'men',\n",
       "  'film',\n",
       "  'world',\n",
       "  'american',\n",
       "  'battle',\n",
       "  'country',\n",
       "  'james',\n",
       "  'shows',\n",
       "  'government'],\n",
       " ['one', 'get', 'movie', 'would', 'like', 'way', 'make', 'two', 'go', 'since'],\n",
       " ['black',\n",
       "  'white',\n",
       "  'three',\n",
       "  'case',\n",
       "  'people',\n",
       "  'years',\n",
       "  'bob',\n",
       "  'become',\n",
       "  'including',\n",
       "  'political'],\n",
       " ['film',\n",
       "  'films',\n",
       "  'even',\n",
       "  'see',\n",
       "  'something',\n",
       "  'get',\n",
       "  'way',\n",
       "  'made',\n",
       "  'story',\n",
       "  'make'],\n",
       " ['john',\n",
       "  'michael',\n",
       "  'star',\n",
       "  'years',\n",
       "  'first',\n",
       "  'george',\n",
       "  'new',\n",
       "  'time',\n",
       "  'best',\n",
       "  'thomas'],\n",
       " ['john',\n",
       "  'dog',\n",
       "  'michael',\n",
       "  'new',\n",
       "  'eddie',\n",
       "  'time',\n",
       "  'sam',\n",
       "  'lost',\n",
       "  'king',\n",
       "  'years'],\n",
       " ['movie',\n",
       "  'would',\n",
       "  'like',\n",
       "  'story',\n",
       "  'rated',\n",
       "  'runs',\n",
       "  'one',\n",
       "  'picture',\n",
       "  'kids',\n",
       "  'little'],\n",
       " ['movie',\n",
       "  'film',\n",
       "  'one',\n",
       "  'dr',\n",
       "  'films',\n",
       "  'special',\n",
       "  'bad',\n",
       "  'new',\n",
       "  'better',\n",
       "  'space'],\n",
       " ['love',\n",
       "  'two',\n",
       "  'comedy',\n",
       "  'characters',\n",
       "  'romantic',\n",
       "  'one',\n",
       "  'together',\n",
       "  'humor',\n",
       "  'romance',\n",
       "  'women'],\n",
       " ['one',\n",
       "  'story',\n",
       "  'like',\n",
       "  'characters',\n",
       "  'makes',\n",
       "  'kate',\n",
       "  'come',\n",
       "  'playing',\n",
       "  'sister',\n",
       "  'sure'],\n",
       " ['man',\n",
       "  'two',\n",
       "  'hes',\n",
       "  'mary',\n",
       "  'john',\n",
       "  'joe',\n",
       "  'brothers',\n",
       "  'night',\n",
       "  'allen',\n",
       "  'family'],\n",
       " ['bond',\n",
       "  'one',\n",
       "  'time',\n",
       "  'school',\n",
       "  'get',\n",
       "  'never',\n",
       "  'high',\n",
       "  'series',\n",
       "  'like',\n",
       "  'around'],\n",
       " ['show',\n",
       "  'movie',\n",
       "  'one',\n",
       "  'film',\n",
       "  'see',\n",
       "  'year',\n",
       "  'films',\n",
       "  'must',\n",
       "  'look',\n",
       "  'excellent'],\n",
       " ['scott',\n",
       "  'see',\n",
       "  'new',\n",
       "  'time',\n",
       "  'room',\n",
       "  'subject',\n",
       "  'details',\n",
       "  'message',\n",
       "  'screening',\n",
       "  'receive'],\n",
       " ['one',\n",
       "  'renshaw',\n",
       "  'also',\n",
       "  'character',\n",
       "  'like',\n",
       "  'characters',\n",
       "  'may',\n",
       "  'story',\n",
       "  'scott',\n",
       "  'might']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[a[0] for a in t[:10]] for t in topic_distributions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
